{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Machine Learning Pipeline\n",
    "## Aim here is to create a list of function, meta functions that can work together \n",
    "## to streamline the process of data cleaning, feature selection and training \n",
    "## our models. This will help into creating more results to focus more time on \n",
    "## optimising models and feature selection than the tiny gritty details of coding\n",
    "\n",
    "\n",
    "\n",
    "######### importing python modules \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pylab as plt \n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def df_importer(name):\n",
    "    # import csv from pandas\n",
    "    dat = pd.read_csv(name)\n",
    "    return dat\n",
    "    \n",
    "def convert_cat_2_num(indat,param):\n",
    "    #convert different categories into a numerical order than can be highly correlated\n",
    "    param_lst = ['Po','Fa','TA','Gd','Ex']\n",
    "    for i in range (len(param_lst)):\n",
    "        try:\n",
    "            indat.loc[indat[param] == param_lst[i], param] = i+1\n",
    "        except:\n",
    "            dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'NA', param] = 0\n",
    "    except:\n",
    "        dum = 1  \n",
    "    try:\n",
    "        indat[param].fillna(0,inplace=True)\n",
    "    except:\n",
    "        dum = 1\n",
    "    return indat\n",
    "\n",
    "def convert_GarageFinish(indat,param='GarageFinish'):\n",
    "    #Convert column GarageFinish to a numerically sensible order\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'Fin', param] = 3\n",
    "    except:\n",
    "        dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'RFn', param] = 2\n",
    "    except:\n",
    "        dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'Unf', param] = 1\n",
    "    except:\n",
    "        dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'NA', param] = 0\n",
    "    except:\n",
    "        dum = 1        \n",
    "    try:\n",
    "        indat[param].fillna(0,inplace=True)\n",
    "    except:\n",
    "        dum = 1\n",
    "    return indat\n",
    "\n",
    "\n",
    "def convert_GarageType(indat,param='GarageType'):\n",
    "    #Convert column GarageType to an order related to median prices\n",
    "    garagetypelst = ['CarPort','Detchd','Basment','2Types','Attchd','BuiltIn']\n",
    "    for i in range (len(garagetypelst)):\n",
    "        try:\n",
    "            indat.loc[indat[param] == garagetypelst[i], param] = i+1\n",
    "        except:\n",
    "            dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'NA', param] = 0\n",
    "    except:\n",
    "        dum = 1        \n",
    "    try:\n",
    "        indat[param].fillna(0,inplace=True)\n",
    "    except:\n",
    "        dum = 1\n",
    "    return indat\n",
    "\n",
    "def convert_Neighborhood(indat,param='Neighborhood'):\n",
    "    #Convert column Neighborhood to a numerically to an order related to median prices\n",
    "    neighborlst = ['MeadowV','IDOTRR','BrDale','OldTown','Edwards','BrkSide','Sawyer','Blueste',\n",
    "                   'SWISU','NAmes','NPkVill','Mitchel','SawyerW','Gilbert','NWAmes','Blmngtn',\n",
    "                    'CollgCr','ClearCr','Crawfor','Veenker','Somerst','Timber','StoneBr','NoRidge','NridgHt']\n",
    "    for i in range (len(neighborlst)):\n",
    "        try:\n",
    "            indat.loc[indat[param] == neighborlst[i], param] = i+1\n",
    "        except:\n",
    "            dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'NA', param] = 0\n",
    "    except:\n",
    "        dum = 1        \n",
    "    try:\n",
    "        indat[param].fillna(0,inplace=True)\n",
    "    except:\n",
    "        dum = 1\n",
    "\n",
    "    return indat\n",
    "\n",
    "def convert_MSZoning(indat,param='MSZoning'):\n",
    "    #Convert column MSZoning to an order related to median prices\n",
    "    param_lst = ['C (all)','RM','RH','RL','FV']\n",
    "    for i in range (len(param_lst)):\n",
    "        try:\n",
    "            indat.loc[indat[param] == param_lst[i], param] = i+1\n",
    "        except:\n",
    "            dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'NA', param] = 0\n",
    "    except:\n",
    "        dum = 1  \n",
    "    try:\n",
    "        indat[param].fillna(0,inplace=True)\n",
    "    except:\n",
    "        dum = 1\n",
    "    return indat\n",
    "\n",
    "def convert_LotShape(indat,param='LotShape'):\n",
    "    #Convert column LotShape to an order related to median prices\n",
    "    param_lst = ['Reg','IR1','IR3','IR2']\n",
    "    for i in range (len(param_lst)):\n",
    "        try:\n",
    "            indat.loc[indat[param] == param_lst[i], param] = i+1\n",
    "        except:\n",
    "            dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'NA', param] = 0\n",
    "    except:\n",
    "        dum = 1  \n",
    "    try:\n",
    "        indat[param].fillna(0,inplace=True)\n",
    "    except:\n",
    "        dum = 1\n",
    "    return indat\n",
    "\n",
    "def convert_BsmtExposure(indat,param='BsmtExposure'):\n",
    "    #Convert column BsmtExposure to an order related to median prices\n",
    "    param_lst = ['No','Mn','Av','Gd']\n",
    "    for i in range (len(param_lst)):\n",
    "        try:\n",
    "            indat.loc[indat[param] == param_lst[i], param] = i+1\n",
    "        except:\n",
    "            dum = 1\n",
    "    try:\n",
    "        indat.loc[indat[param] == 'NA', param] = 0\n",
    "    except:\n",
    "        dum = 1  \n",
    "    try:\n",
    "        indat[param].fillna(0,inplace=True)\n",
    "    except:\n",
    "        dum = 1\n",
    "    return indat\n",
    "\n",
    "\n",
    "def convert_all_categories(indat):\n",
    "    ## meta converter. if used, the following columns of any dataframe will be converted to numerical column:\n",
    "    # 'ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond'\n",
    "    # 'Neighborhood', 'GarageFinish', 'GarageType', 'Neighborhood', 'MSZoning', 'LotShape', 'BsmtExposure'\n",
    "    list_cat_num = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond']\n",
    "    \n",
    "    for i in range(len(list_cat_num)):\n",
    "        convert_cat_2_num(indat,list_cat_num[i])\n",
    "\n",
    "    indat = convert_Neighborhood(indat)\n",
    "    indat = convert_GarageFinish(indat)\n",
    "    indat = convert_GarageType(indat)\n",
    "    indat = convert_Neighborhood(indat)\n",
    "    indat = convert_MSZoning(indat)\n",
    "    indat = convert_LotShape(indat)\n",
    "    indat = convert_BsmtExposure(indat)\n",
    "    return indat\n",
    "\n",
    "\n",
    "def load_converted_df(name):\n",
    "    # load dataframe and convert categorical features into meaningful number.\n",
    "    df = df_importer(name)\n",
    "    df1 = convert_all_categories(df)\n",
    "    return df1\n",
    "\n",
    "def create_spearman_corr_plot(df_in):\n",
    "    # creates the spearman correlation plot for all numerical parameters\n",
    "    plt.style.use('ggplot')\n",
    "    spearman_corr = df_in.corr(method='spearman')\n",
    "    fig = plt.figure(figsize=(10,17))\n",
    "    plt.title('Spearman correlation with sale prices')\n",
    "    spearman_corr['SalePrice'].plot.barh()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_cv(model,df_in,x_arr,y_arr):\n",
    "    n_folds = 5\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(df_in.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, x_arr, y_arr, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "def print_res(selec_mod,mod,df_in,x_arr,y_arr):\n",
    "    score = rmsle_cv(mod,df_in,x_arr,y_arr)\n",
    "    print(\"\\n \"+selec_mod+\" score: {:.4f}% ({:.4f})\\n\".format(score.mean()*100, score.std()*100))\n",
    "    return\n",
    "\n",
    "def ML_models(selec_mod,df_in,x_arr,y_arr,x_tes):\n",
    "    # selec_mod: select model\n",
    "    # df_in - input dataframe - train DF\n",
    "    # x_arr = X_train\n",
    "    # y_arr = Y_train\n",
    "    # x_tes = X_test\n",
    "\n",
    "    if selec_mod == 'lasso':\n",
    "        model_lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "        print_res(selec_mod,model_lasso,df_in,x_arr,y_arr)\n",
    "        model_lasso.fit(x_arr,y_arr)\n",
    "        prediction = model_lasso.predict(x_arr)\n",
    "        print (1-model_lasso.score(x_arr,y_arr))*100\n",
    "        prediction1 = model_lasso.predict(x_tes)\n",
    "        return prediction1,model_lasso\n",
    "    \n",
    "    if selec_mod == 'Enet':\n",
    "        model_ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "        print_res(selec_mod,model_ENet,df_in,x_arr,y_arr)\n",
    "        model_ENet.fit(x_arr,y_arr)\n",
    "        prediction = model_ENet.predict(x_arr)\n",
    "        print (1-model_ENet.score(x_arr,y_arr))*100\n",
    "        prediction1 = model_ENet.predict(x_tes)\n",
    "        return prediction1,model_ENet\n",
    "    \n",
    "    if selec_mod == 'KRR':\n",
    "        model_KRR = make_pipeline(RobustScaler(), KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5))\n",
    "        print_res(selec_mod,model_KRR,df_in,x_arr,y_arr)\n",
    "        model_KRR.fit(x_arr,y_arr)\n",
    "        prediction = model_KRR.predict(x_arr)\n",
    "        print (1-model_KRR.score(x_arr,y_arr))*100\n",
    "        prediction1 = model_KRR.predict(x_tes)\n",
    "        return prediction1,model_KRR\n",
    "    \n",
    "    if selec_mod == 'GBoost':\n",
    "        model_GBoost = make_pipeline(RobustScaler(), GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5))\n",
    "\n",
    "        print_res(selec_mod,model_GBoost,df_in,x_arr,y_arr)\n",
    "        model_GBoost.fit(x_arr,y_arr)\n",
    "        prediction = model_KRR.predict(x_arr)\n",
    "        print (1-model_KRR.score(x_arr,y_arr))*100\n",
    "        prediction1 = model_KRR.predict(x_tes)\n",
    "        return prediction1,model_GBoost\n",
    "    \n",
    "    if selec_mod == 'xbg':\n",
    "        model_xgb = make_pipeline(RobustScaler(), xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1))\n",
    "        \n",
    "        print_res(selec_mod,model_xgb,df_in,x_arr,y_arr)\n",
    "        model_xgb.fit(x_arr,y_arr)\n",
    "        prediction = model_xgb.predict(x_arr)\n",
    "        print (1-model_xgb.score(x_arr,y_arr))*100\n",
    "        prediction1 = model_xgb.predict(x_tes)\n",
    "        return prediction1,model_xgb\n",
    "    \n",
    "    if selec_mod == 'lgb':\n",
    "        model_lgb = make_pipeline(RobustScaler(),lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11))\n",
    "        \n",
    "        print_res(selec_mod,model_lgb,df_in,x_arr,y_arr)\n",
    "        model_lgb.fit(x_arr,y_arr)\n",
    "        prediction = model_lgb.predict(x_arr)\n",
    "        print (1-model_lgb.score(x_arr,y_arr))*100\n",
    "        prediction1 = model_lgb.predict(x_tes)\n",
    "        return prediction1,model_lgb\n",
    "\n",
    "    if selec_mod == 'randomforrest':\n",
    "        model_randomfor = make_pipeline(RobustScaler(), RandomForestRegressor(n_estimators=45,criterion='mse'))\n",
    "\n",
    "        print_res(selec_mod,model_randomfor,df_in,x_arr,y_arr)\n",
    "        model_randomfor.fit(x_arr,y_arr)\n",
    "        prediction = model_randomfor.predict(x_arr)\n",
    "        print (1-model_randomfor.score(x_arr,y_arr))*100  \n",
    "        prediction1 = model_randomfor.predict(x_tes)\n",
    "        return prediction1,model_randomfor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_lst = ['HeatingQC','Foundation','Fireplaces','TotRmsAbvGrd','YearRemodAdd','1stFlrSF',\n",
    "            'GarageType','TotalBsmtSF','GarageFinish','FullBath','GarageArea','YearBuilt',\n",
    "            'KitchenQual','BsmtQual','ExterQual','GarageCars','GrLivArea','Neighborhood','OverallQual','SalePrice']\n",
    "\n",
    "feature_drop = ['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n",
    "\n",
    "def feature_selection(df_in,feature_lst,feature_drop):\n",
    "    #function to select and drop features from a dataframe. \n",
    "    df_in = df_in.drop(feature_drop,axis=1)\n",
    "    df_in = df_in[feature_lst]\n",
    "    return df_in\n",
    "\n",
    "def label_encoding(df_in):\n",
    "    #function to use label encoder to encode string columns - returns numerical columns \n",
    "    dfin_str = df_in.select_dtypes(include=['object'])\n",
    "\n",
    "    for col in dfin_str:\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(df_in[col].values)) \n",
    "        df_in[col] = lbl.transform(list(df_in[col].values))\n",
    "    return df_in\n",
    "\n",
    "\n",
    "### Loading csv file and converting specific categorical data into meaningful name\n",
    "train = load_converted_df('train.csv')\n",
    "test = load_converted_df('test.csv')\n",
    "\n",
    "#encoding remaining categorical data with one-hot-encoder\n",
    "training = label_encoding(train)\n",
    "#feature selection of the training set\n",
    "training_set = feature_selection(training,feature_lst,feature_drop)\n",
    "\n",
    "testing = label_encoding(test)\n",
    "testing_set = feature_selection(testing,feature_lst[:-1],feature_drop)\n",
    "testing_set = testing_set.fillna(0)\n",
    "\n",
    "#dividing training data into independent variable (X) and dependent variable (Y)\n",
    "X_train = training_set.iloc[:,:-1].values\n",
    "Y_train = np.log(training_set.iloc[:,-1].values)\n",
    "\n",
    "X_test = testing_set.iloc[:,:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " lasso score: 15.5279% (1.8523)\n",
      "\n",
      "14.1448054635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 11.67488275,  11.85699186,  12.0378066 , ...,  11.9281727 ,\n",
       "         11.61574068,  12.2940295 ]), Pipeline(memory=None,\n",
       "      steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
       "        with_scaling=True)), ('lasso', Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=1,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False))]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling an ML model to fit to the data\n",
    "\n",
    "ML_models('lasso',training_set,X_train,Y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
